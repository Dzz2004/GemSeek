{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2dd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f851030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文本分析工具\n",
    "model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7246192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "reviews_path = '../city_filter/reviews_Indianapolis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d1b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a list of texts using a pre-trained model.\n",
    "    params:\n",
    "        text: strings to analyze\n",
    "    returns:\n",
    "        probabilities: tensor of sentiment probabilities [Very Negative, Negative, Neutral, Positive, Very Positive]\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143092d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0193, 0.0216, 0.0845, 0.2901, 0.5844]])\n"
     ]
    }
   ],
   "source": [
    "text = \"I love this place!\"\n",
    "sentiments = predict_sentiment(text)\n",
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a774265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use slide window to process long text\n",
    "def slide_window_analysis(text, window_size=512, step_size=256):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks for processing.\n",
    "    params:\n",
    "        text: string to analyze\n",
    "        window_size: size of each chunk\n",
    "        step_size: size of the overlap between chunks\n",
    "    returns:\n",
    "        sentiment: sentiment label\n",
    "    \"\"\"\n",
    "    sentiment_map = {\n",
    "        0: 'Very Negative',\n",
    "        1: 'Negative',\n",
    "        2: 'Neutral',\n",
    "        3: 'Positive',\n",
    "        4: 'Very Positive'\n",
    "    }\n",
    "\n",
    "    tokens = tokenizer.encode(text)\n",
    "\n",
    "    # 如果长度小于512，直接分析\n",
    "    if len(tokens) < 512:\n",
    "        probabilities = predict_sentiment(text)\n",
    "        sentiment = sentiment_map[int(torch.argmax(probabilities))]\n",
    "        return sentiment\n",
    "    \n",
    "    # 如果长度大于512，使用滑动窗口方法\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(tokens), step_size):\n",
    "        chunk = tokens[i:i + window_size]\n",
    "        if len(chunk) == 0:\n",
    "            break\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "\n",
    "    # 确保最后一块也被包含\n",
    "    if len(tokens) > 0:\n",
    "        last_chunk = tokenizer.decode(tokens[-window_size:])\n",
    "        if last_chunk not in chunks:\n",
    "            chunks.append(last_chunk)\n",
    "\n",
    "    # analyze each chunk\n",
    "    sentiment_probabilities = []\n",
    "    for chunk in chunks:\n",
    "        probabilities = predict_sentiment(chunk)\n",
    "        sentiment_probabilities.append(probabilities)\n",
    "    # combine sentiments by average\n",
    "    sentiment_probabilities = torch.mean(torch.stack(sentiment_probabilities), dim=0)\n",
    "    sentiment = sentiment_map[int(torch.argmax(sentiment_probabilities))]\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae219f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "long_text = [\"I've been visiting this restaurant for years, and honestly, it's a bit of a mixed bag. The ambiance is cozy, and the staff are usually friendly, though sometimes service can be a little slow, especially on weekends. I really enjoy the pasta—they make it fresh, and you can taste the difference. Their tiramisu is easily one of the best in town, super creamy and not too sweet. That said, their coffee could use some work—it’s often too bitter or burnt-tasting. Prices have gone up lately, which is understandable, but still noticeable. On my last visit, they accidentally messed up my order, but the manager came over personally to apologize and comped the dish. That level of customer service keeps me coming back. Overall, while it's not perfect, it’s one of the more reliable places around, and I always leave feeling satisfied. Definitely worth a try if you’re in the neighborhood and craving Italian.\"]\n",
    "print(slide_window_analysis(long_text[0], window_size=512, step_size=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a051fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_path = '../yelp_reviews_first100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ef5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析评论\n",
    "def review_analysis(reviews_path, output_path):\n",
    "    \"\"\"\n",
    "    Analyze reviews from a CSV file and save the results to a new CSV file.\n",
    "    Each 'text' is replaced with its sentiment label.\n",
    "    \n",
    "    :param reviews_path: str, path to input CSV with reviews\n",
    "    :param output_path: str, path to save the output CSV with sentiments\n",
    "    \"\"\"\n",
    "    processed_rows = []\n",
    "\n",
    "    with open(reviews_path, 'r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for i, row in tqdm(enumerate(reader),total=361701):\n",
    "            review_text = row['text']\n",
    "            sentiment = slide_window_analysis(review_text)\n",
    "            row['text'] = sentiment  # 替换原来的文本为情感标签\n",
    "            processed_rows.append(row)\n",
    "\n",
    "\n",
    "    # 写入新CSV\n",
    "    with open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(processed_rows)\n",
    "\n",
    "    print(f\"情感分析完成，结果已保存至: {output_path}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"reviews_Indianapolis_analyzed.csv\"\n",
    "review_analysis(reviews_path=reviews_path,output_path=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dzz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
