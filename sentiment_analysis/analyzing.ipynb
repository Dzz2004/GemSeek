{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a2dd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f851030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载文本分析工具\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Load the model and tokenizer\n",
    "model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7246192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "reviews_path = '../city_filter/reviews_Indianapolis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0d1b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_slide_window_sentiment(text_list, window_size=512, step_size=256):\n",
    "    \"\"\"\n",
    "    对一个文本列表进行滑动窗口情感分析，每个文本由多个窗口组成，最终平均得出整体情感。\n",
    "    \"\"\"\n",
    "    sentiment_map = {\n",
    "        0: 'Very Negative',\n",
    "        1: 'Negative',\n",
    "        2: 'Neutral',\n",
    "        3: 'Positive',\n",
    "        4: 'Very Positive'\n",
    "    }\n",
    "\n",
    "    all_chunks = []\n",
    "    chunk_mapping = []  # [(start_idx_in_all_chunks, num_chunks)]，每条原始文本映射\n",
    "\n",
    "    for text in text_list:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "        chunks = []\n",
    "\n",
    "        if len(tokens) <= window_size:\n",
    "            chunks.append(text)\n",
    "        else:\n",
    "            for i in range(0, len(tokens), step_size):\n",
    "                chunk = tokens[i:i + window_size]\n",
    "                if chunk:\n",
    "                    chunks.append(tokenizer.decode(chunk))\n",
    "            # 确保最后一个 chunk 包含尾部\n",
    "            if tokenizer.decode(tokens[-window_size:]) not in chunks:\n",
    "                chunks.append(tokenizer.decode(tokens[-window_size:]))\n",
    "\n",
    "        start = len(all_chunks)\n",
    "        all_chunks.extend(chunks)\n",
    "        chunk_mapping.append((start, len(chunks)))\n",
    "\n",
    "    # Tokenize and move to device\n",
    "    inputs = tokenizer(all_chunks, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Aggregate results per original text\n",
    "    results = []\n",
    "    for start, count in chunk_mapping:\n",
    "        chunks_probs = probs[start:start + count]\n",
    "        avg_prob = torch.mean(chunks_probs, dim=0)\n",
    "        label = torch.argmax(avg_prob).item()\n",
    "        results.append(sentiment_map[label])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a051fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_path = '../yelp_reviews_first100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1ef5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析评论\n",
    "def analyze_reviews_with_sentiment(input_csv_path, output_csv_path, batch_size=32):\n",
    "    \"\"\"\n",
    "    从CSV中读取'review'文本，进行批量情感分析，将结果写入新CSV。\n",
    "    原 'text' 字段会被情感标签替代。\n",
    "    \"\"\"\n",
    "    with open(input_csv_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_csv_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        batch_rows = []\n",
    "        batch_texts = []\n",
    "\n",
    "        for row in tqdm(reader, desc=\"Analyzing\", total=361701):\n",
    "            batch_rows.append(row)\n",
    "            batch_texts.append(row['text'])\n",
    "\n",
    "            if len(batch_rows) >= batch_size:\n",
    "                sentiments = batch_slide_window_sentiment(batch_texts)\n",
    "                for r, s in zip(batch_rows, sentiments):\n",
    "                    r['text'] = s\n",
    "                    writer.writerow(r)\n",
    "                batch_rows = []\n",
    "                batch_texts = []\n",
    "\n",
    "        # 写入最后不足一个 batch 的数据\n",
    "        if batch_rows:\n",
    "            sentiments = batch_slide_window_sentiment(batch_texts)\n",
    "            for r, s in zip(batch_rows, sentiments):\n",
    "                r['text'] = s\n",
    "                writer.writerow(r)\n",
    "\n",
    "    print(f\"情感分析完成，结果保存至：{output_csv_path}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af5d0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|█████████▉| 361626/361701 [31:12<00:00, 193.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感分析完成，结果保存至：reviews_Indianapolis_analyzed.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"reviews_Indianapolis_analyzed.csv\"\n",
    "analyze_reviews_with_sentiment(reviews_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dzz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
