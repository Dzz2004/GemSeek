# è¯„è®ºç‰¹å¾æå–æŠ¥å‘Š | Review Feature Extraction Report

- ğŸ“ æºä»£ç  / Source Code: `review_feature.ipynb`  
- ğŸ“Š å¯è§†åŒ– / Visualization:  
  - `avg_review_stars_distribution.png`ï¼ˆå¹³å‡è¯„åˆ†åˆ†å¸ƒï¼‰  
  - `overall_sentiment_composition.png`ï¼ˆè¯„è®ºæƒ…æ„Ÿç»„æˆï¼‰

- ğŸ“ è¾“å‡º/ Output: `business_review_Indianapolis_features.csv`



## ğŸ§  é¡¹ç›®èƒŒæ™¯ | Background

æœ¬é˜¶æ®µæ—¨åœ¨ä» Yelp è¯„è®ºæ•°æ®ä¸­æå–ç”¨äºå•†å®¶è¯†åˆ«ä¸è´¨é‡è¯„ä¼°çš„å…³é”®è¯„è®ºç‰¹å¾ï¼Œä¸ºåç»­çš„å»ºæ¨¡ä¸åˆ†æï¼ˆå¦‚â€œè¢«åŸ‹æ²¡çš„ä¼˜è´¨å•†å®¶è¯†åˆ«â€ï¼‰æä¾›ç»“æ„åŒ–è¾“å…¥ã€‚

The goal of this phase is to extract key review-level features from Yelp data to support the downstream task of identifying high-quality yet underrated businesses.



## ğŸ”§ æ•°æ®æºä¸å¤„ç† | Data Sources & Processing

- **æƒ…æ„Ÿåˆ†ææ•°æ®**ï¼šå·²é€šè¿‡æ»‘åŠ¨çª—å£æŠ€æœ¯å¯¹åŸå§‹è¯„è®ºæ–‡æœ¬è¿›è¡Œå¤„ç†ï¼Œå¹¶ä½¿ç”¨æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹è¾“å‡ºæ ‡ç­¾ï¼ˆVery_Negative ~ Very_Positiveï¼‰
- **åŸå§‹è¯„è®ºæ–‡æœ¬æ•°æ®**ï¼šç”¨äºæå–æ–‡æœ¬é•¿åº¦ã€äº’åŠ¨æ€§ç­‰åŸå§‹ç‰¹å¾
- **å•†å®¶ç­›é€‰ä¿¡æ¯**ï¼šä»…ä¿ç•™å‡ºç°åœ¨æœ€ç»ˆå•†å®¶é›†åˆï¼ˆ`business_df`ï¼‰ä¸­çš„å•†å®¶

We used two types of review data: sentiment-labeled data and raw text data. Features are aggregated only for businesses listed in our filtered set.



## ğŸ§© ç‰¹å¾æå–ç»´åº¦ | Extracted Feature Dimensions

### 1. ğŸŒŸ è¯„åˆ†ç‰¹å¾ | Rating Features

| ç‰¹å¾å | æè¿° |
|--|--|
| `avg_review_stars` | å•†å®¶è¯„è®ºæ˜Ÿçº§çš„å¹³å‡å€¼ |
| `std_review_stars_scaled` | å•†å®¶è¯„åˆ†æ ‡å‡†å·®ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰ |

> è¯„åˆ†æ ‡å‡†å·®åæ˜ ç”¨æˆ·è¯„ä»·çš„ä¸€è‡´æ€§æˆ–åˆ†æ­§ï¼Œç»è¿‡æ ‡å‡†åŒ–å¤„ç†æå‡äº†å»ºæ¨¡å¯æ¯”æ€§ã€‚

The average and variability of review scores were captured. Standard deviation was scaled to unify its magnitude with other numeric features.



### 2. â¤ï¸ æƒ…æ„Ÿç‰¹å¾ | Sentiment Features

| ç‰¹å¾å | æè¿° |
|--|---|
| `sentiment_score_mean_scaled` | æƒ…æ„Ÿå¾—åˆ†å‡å€¼ï¼ˆæ˜ å°„å [-2, 2]ï¼Œå¹¶æ ‡å‡†åŒ–ï¼‰ |
| `pos_review_ratio`, `neg_review_ratio`, `neu_review_ratio` | ä¸åŒæƒ…æ„Ÿå æ¯” |

> æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„ä¸ºæ•´æ•°å€¼åæ±‚å‡å€¼ï¼Œå¯é‡åŒ–å•†å®¶æ•´ä½“è¯„è®ºæƒ…ç»ªå€¾å‘ï¼›åŒæ—¶ä¿ç•™ä¸åŒæƒ…æ„Ÿç±»å‹çš„ç›¸å¯¹å æ¯”ä¿¡æ¯ã€‚

Sentiment labels were mapped to integer scores and averaged. The ratio of positive, negative, and neutral comments was also calculated for interpretability.



### 3. âœï¸ å†…å®¹ç‰¹å¾ | Textual Features

| ç‰¹å¾å | æè¿° |
|--|--|
| `avg_review_length_scaled`, `avg_word_count_scaled` | å¹³å‡å­—ç¬¦æ•°ä¸è¯æ•°ï¼ˆæ ‡å‡†åŒ–ï¼‰ |
| `long_review_ratio` | è¶…è¿‡ 300 å­—çš„é•¿è¯„è®ºå æ¯” |

> è¯„è®ºé•¿åº¦ç»è¿‡ `log(1+x)` è½¬æ¢å’Œæ ‡å‡†åŒ–ï¼Œæ§åˆ¶é•¿å°¾åˆ†å¸ƒï¼›é•¿è¯„è®ºé€šå¸¸åŒ…å«æ›´æ·±å…¥çš„å†…å®¹ã€‚

Comment length features were transformed and scaled to reduce skewness. Long reviews were considered to contain more informative feedback.



### 4. ğŸ™‹â€â™€ï¸ äº’åŠ¨ç‰¹å¾ | Interaction Features

| ç‰¹å¾å | æè¿° |
|--|--|
| `avg_useful_scaled`, `avg_funny_scaled`, `avg_cool_scaled` | å„ç±»äº’åŠ¨ç¥¨æ•°ï¼ˆæ ‡å‡†åŒ–ï¼‰ |
| `interact_score_mean_scaled` | è‡ªå®šä¹‰åŠ æƒäº’åŠ¨å¾—åˆ†ï¼ˆuseful + 0.5Ã—funny + 0.2Ã—coolï¼‰ |

> äº’åŠ¨æ€§åæ˜ è¯„è®ºè¢«è¯»è€…å…³æ³¨å’Œè®¤å¯çš„ç¨‹åº¦ï¼ŒåŠ æƒæ–¹å¼ä½“ç°â€œä¿¡æ¯ä»·å€¼ > æƒ…ç»ªé©±åŠ¨â€çš„é‡è¦æ€§æ’åºã€‚

The interaction score aggregates user engagement signals with weighted importance. Useful votes dominate, while funny and cool provide secondary indicators.



### 5. ğŸ“† æ—¶é—´ç‰¹å¾ | Temporal Features

| ç‰¹å¾å | æè¿° |
|--|---|
| `recent_review_ratio` | æœ€è¿‘ä¸€å¹´è¯„è®ºå æ€»è¯„è®ºçš„æ¯”ä¾‹ |
| `review_timespan_days_scaled` | è¯„è®ºæ—¶é—´è·¨åº¦ï¼ˆæ ‡å‡†åŒ–ï¼‰ |
| `review_density_per_day_scaled` | å¹³å‡æ¯æ—¥è¯„è®ºå¯†åº¦ |
| `review_burst_score_scaled` | è¿‘æœŸçƒ­åº¦çˆ†å‘åº¦ï¼ˆè¿‘æœŸè¯„è®ºæ¯”ä¾‹ / æ€»è·¨åº¦å¤©æ•°ï¼‰ |
| `first_review_date`, `last_review_date` | é¦–/æœ«æ¡è¯„è®ºæ—¶é—´ï¼ˆä¿ç•™ datetime æ ¼å¼ï¼‰ |


> å°½ç®¡ Yelp æ•°æ®é›†å·²äº 2021 å¹´åœæ›´ï¼Œæ—¶é—´ç±»ç‰¹å¾ä»æä¾›äº†å•†å®¶è¯„è®ºç”Ÿå‘½å‘¨æœŸçš„å…³é”®ä¿¡æ¯ã€‚

Though the Yelp dataset is historical, relative time-based features still capture business activeness and lifecycle trends.



## ğŸ“Š å¯è§†åŒ–å›¾ç¤º | Visualizations

### â­ å•†å®¶å¹³å‡è¯„åˆ†åˆ†å¸ƒ | Average Star Distribution

![avg_review_stars_distribution](avg_review_stars_distribution.png)

### ğŸ§  è¯„è®ºæƒ…æ„Ÿç»„æˆ | Overall Sentiment Composition

![overall_sentiment_composition](overall_sentiment_composition.png)



## âœ… æ€»ç»“ | Summary

æœ¬è½®è¯„è®ºç‰¹å¾æå–ä»è¯„åˆ†ã€æƒ…æ„Ÿã€å†…å®¹ã€äº’åŠ¨ã€æ—¶é—´äº”ä¸ªç»´åº¦æ„å»ºäº†è¾ƒä¸ºå®Œæ•´çš„å•†å®¶è¯„è®ºç”»åƒï¼Œä¸ºåç»­çš„å†·é—¨ä¼˜è´¨å•†å®¶æŒ–æ˜ï¼ˆGemSeekï¼‰ä»»åŠ¡æ‰“ä¸‹äº†åšå®åŸºç¡€ã€‚

This review feature extraction phase constructed a rich set of descriptors capturing multiple aspects of customer feedback. These features will play a critical role in discovering high-quality, underrated businesses.



